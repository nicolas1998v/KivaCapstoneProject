{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING - EXTRA VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Modelling Notebook of the Kiva Capstone Project! This notebook's purpose is to see if people take into account default and delinquency rates when choosing whether to fund a loan on Kiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('/Users/nicolas/Downloads/loans2_data_modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = loans['status']\n",
    "X = loans.copy().drop('status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1382664\n",
       "1      75913\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start with some basic models to have a baseline score we need to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(\n",
    "    X,y, stratify=y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "rf.fit(x_train, y_train)\n",
    "print(rf.score(x_test, y_test))\n",
    "x_predrf = rf.predict(x_test)\n",
    "print(precision_score(y_test,x_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(x_train, y_train)\n",
    "print(logreg.score(x_test, y_test))\n",
    "x_predlr = logreg.predict(x_test)\n",
    "print(precision_score(y_test,x_predlr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INBALANCE CLASSIFICATION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there is a severe imbalance in class labels, as the occurance of class 1 happens only 0.045% of the time. To cope with this challenge, I tried two methods : Cost Sensitive methods and Sampling Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COST SENSITIVE METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Sensitive methods consist in tuning the 'class_weight' parameter which gives slightly more importance to the minority class when modelling. Grisearch instantiates many models and brings back the one with the highest precision. Tried it both with random forests and logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'class_weight': [{0:0.01,1:0.02},{0:0.01,1:0.03},{0:0.01,1:0.4}]}\n",
    "gs = GridSearchCV(estimator= RandomForestClassifier(n_estimators=100),\n",
    "                  param_grid=params,\n",
    "                  cv=5,\n",
    "                  scoring='precision',\n",
    "                  verbose=1)\n",
    "# fit the gridsearch object on your training data\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "# extract the grid search results\n",
    "# print out the best parameters\n",
    "print('Best Parameters:')\n",
    "print(gs.best_params_)\n",
    "# print out the best mean cross-validated score\n",
    "print('Best estimator mean cross validated training score:')\n",
    "print(gs.best_score_)\n",
    "print('Best estimator score on the full training set:')\n",
    "print(gs.score(x_train, y_train))\n",
    "# score your model on your testing data\n",
    "print('Best estimator score on the test set:')\n",
    "print(gs.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'class_weight': [{0:0.01,1:0.03},{0:0.01,1:0.4},{0:0.01,1:0.05}]}\n",
    "gs3 = GridSearchCV(estimator= RandomForestClassifier(n_estimators=100),\n",
    "                  param_grid=params,\n",
    "                  cv=5,\n",
    "                  scoring='precision',\n",
    "                  verbose=1)\n",
    "# fit the gridsearch object on your training data\n",
    "gs3.fit(x_train, y_train)\n",
    "\n",
    "# extract the grid search results\n",
    "# print out the best parameters\n",
    "print('Best Parameters:')\n",
    "print(gs3.best_params_)\n",
    "# print out the best mean cross-validated score\n",
    "print('Best estimator mean cross validated training score:')\n",
    "print(gs3.best_score_)\n",
    "print('Best estimator score on the full training set:')\n",
    "print(gs3.score(x_train, y_train))\n",
    "# score your model on your testing data\n",
    "print('Best estimator score on the test set:')\n",
    "print(gs3.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'class_weight': [{0:0.01,1:0.01},{0:0.01,1:0.02},{0:0.01,1:0.03}]}\n",
    "gs2 = GridSearchCV(estimator= LogisticRegression(max_iter = 10000),\n",
    "                  param_grid=params,\n",
    "                  cv=5,\n",
    "                  scoring='precision',\n",
    "                  verbose=1)\n",
    "# fit the gridsearch object on your training data\n",
    "gs2.fit(x_train, y_train)\n",
    "\n",
    "# extract the grid search results\n",
    "# print out the best parameters\n",
    "print('Best Parameters:')\n",
    "print(gs2.best_params_)\n",
    "# print out the best mean cross-validated score\n",
    "print('Best estimator mean cross validated training score:')\n",
    "print(gs2.best_score_)\n",
    "print('Best estimator score on the full training set:')\n",
    "print(gs2.score(x_train, y_train))\n",
    "# score your model on your testing data\n",
    "print('Best estimator score on the test set:')\n",
    "print(gs2.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csrf = gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_csrf = csrf.predict(x_test)\n",
    "print(accuracy_score(y_test,x_pred_csrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLING METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method we can try is using Random Sampling to sample the training set in order to train on better proportions of class label percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "x_train,x_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=1)\n",
    "x_train,y_train = over.fit_resample(x_train,y_train)\n",
    "x_train, y_train = under.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srf = RandomForestClassifier(n_estimators = 300)\n",
    "srf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_srf = srf.predict(x_test)\n",
    "print(precision_score(y_test,x_pred_srf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LogisticRegression(max_iter=10000)\n",
    "slr.fit(x_train, y_train)\n",
    "\n",
    "print(slr.score(x_test, y_test))\n",
    "\n",
    "x_pred_slr = slr.predict(x_test)\n",
    "print(precision_score(y_test,x_pred_slr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostedrf = AdaBoostClassifier(base_estimator=rf,\n",
    "                           random_state=1)\n",
    "boostedrf.fit(x_train, y_train)\n",
    "\n",
    "print(boostedrf.score(x_test, y_test))\n",
    "\n",
    "x_pred_brf = boostedrf.predict(x_test)\n",
    "print(precision_score(y_test,x_pred_brf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the confusion matrices of our 2 best models, the basic random forest and the cost-sensitive random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "plot_confusion_matrix(rf, x_train, y_train, cmap='Blues',ax=ax[0])\n",
    "plot_confusion_matrix(rf, x_test, y_test, cmap='Blues', ax=ax[1])\n",
    "\n",
    "for a in ax:\n",
    "    texts = a.texts\n",
    "    for text in texts:\n",
    "        text.set_size(20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "plot_confusion_matrix(csrf, x_train, y_train, cmap='Blues',ax=ax[0])\n",
    "plot_confusion_matrix(csrf, x_test, y_test, cmap='Blues', ax=ax[1])\n",
    "\n",
    "for a in ax:\n",
    "    texts = a.texts\n",
    "    for text in texts:\n",
    "        text.set_size(20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84/(494+84) = 0.145. \n",
    "113 / (113+603) = 0.157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our best model, 14.5% of loans promoted would actually be False Positives, or loans which would have been funded either way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf,'model_rf_0.857')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the coeffients and feature importances of the basic logistic regression and random forests, which are also our best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_logreg = pd.DataFrame({\n",
    "    'coef': logreg.coef_[0],\n",
    "    'variable': X.columns,\n",
    "    'abscoef': np.abs(logreg.coef_[0])\n",
    "})\n",
    "coefs_logreg.sort_values('abscoef', ascending=False, inplace=True)\n",
    "coefs_logreg.head(30).plot(kind='barh', x='variable', y='coef',\n",
    "                      color='g', figsize=(12, 12), label='coef')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_rf = pd.DataFrame({\n",
    "    'feature_importances': rf.feature_importances_,\n",
    "    'variable': X.columns})\n",
    "coefs_rf.sort_values('feature_importances', ascending=False, inplace=True)\n",
    "coefs_rf.head(40).plot(kind='barh', x='variable', y='feature_importances',\n",
    "                      color='b', figsize=(12, 12), label='Coef')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_roc_curve(csrf, X, y, ax=ax)\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_precision_recall_curve(csrf, X, y, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
